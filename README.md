# Voice-Emotion-Classification

• Developed a deep learning model using Keras and MFCC features via Librosa to classify speech into 7 emotional
• Processed 5,600+ audio files in the TESS dataset; visualized waveforms and spectrograms for detailed analysis
• Achieved 100% validation accuracy using a multi-layer LSTM, showcasing strong temporal pattern recognition
• Focused on mental health monitoring, sentiment analysis, and AI-human interaction in AI-driven social application
